"""
Open Field Behavior Analysis Script for DeepLabCut Data

Description:
    This script processes CSV files generated by DeepLabCut to analyze open field behavior.
    It calculates standard metrics (distance, speed, center entries) AND 
    rotational metrics (Absolute Cumulative Circles).

    The script assumes the DeepLabCut output CSV format (multi-level headers).
    It filters low-likelihood tracking points and interpolates missing data.
"""

import pandas as pd
import numpy as np
import os
import traceback
from scipy.ndimage import label

# ==========================================
# --- CONFIGURATION PARAMETERS ---
# ==========================================

# 1. Input Files
# List the full paths to the CSV files you want to analyze.
CSV_FILE_PATHS = [
    # "path/to/your/file1.csv",
    # "path/to/your/file2.csv",
]

# 2. Experimental Setup
PIXEL_MAX = 500         # The width/height of the arena in pixels
CM_MAX = 50             # The physical width/height of the arena in centimeters
LIKELIHOOD_THRESH = 0.60 # Confidence threshold for DLC tracking
FRAME_RATE = 30         # Video frame rate (fps)
BODY_PART = 'HEAD'      # The body part to track (must match DLC config)

# 3. Center Zone Definition
FIELD_SIZE_CM = 50      # Total size of the field (cm)
CENTER_SIZE_CM = 30     # Size of the defined center zone (cm)

# 4. Rotation Analysis Parameters
# Minimum speed to consider the animal is "moving" for rotation calculation
LOCOMOTION_THRESH_CM_S = 5.0 
# Window size to calculate direction vectors (smoothing factor for rotation)
WINDING_WINDOW_FRAMES = 10   

# 5. Output Filename
OUTPUT_FILENAME = 'open_field_analysis_summary.csv'


# ==========================================
# --- HELPER FUNCTIONS ---
# ==========================================

def pixel_to_cm(pixel_series, pixel_max=PIXEL_MAX, cm_max=CM_MAX):
    """Convert pixel coordinates to centimeters."""
    return pixel_series * cm_max / pixel_max

def calculate_absolute_circles(x_series, y_series, likelihood_series):
    """
    Calculate the Absolute Cumulative Circles (total rotation regardless of direction).
    
    Logic:
    1. Filter data by likelihood.
    2. Filter segments where the animal is moving faster than LOCOMOTION_THRESH_CM_S.
    3. Calculate turning angles using a sliding window to determine direction vectors.
    4. Sum absolute turning angles and divide by 2*pi.
    """
    try:
        # Prepare data
        coords = np.column_stack((x_series.to_numpy(), y_series.to_numpy()))
        likelihood = likelihood_series.to_numpy()
        
        # Filter by likelihood
        mask = likelihood >= LIKELIHOOD_THRESH
        if np.sum(mask) < WINDING_WINDOW_FRAMES * 3:
            return 0.0
        
        # Use only valid coordinates for vector calculation
        # (Note: In the main function we interpolate, but here we strictly check validity if needed,
        # but since we pass interpolated data from main, we assume x/y are clean)
        valid_coords = coords # Coords are already interpolated in main function
        
        # Calculate dynamic speed threshold in pixels/frame
        # 1 cm = (PIXEL_MAX / CM_MAX) pixels
        px_per_cm = PIXEL_MAX / CM_MAX
        speed_thresh_px_frame = (LOCOMOTION_THRESH_CM_S * px_per_cm) / FRAME_RATE

        # Calculate displacements (speed)
        displacements = np.sqrt(np.sum(np.diff(valid_coords, axis=0)**2, axis=1))
        
        # Identify moving frames
        is_moving = displacements > speed_thresh_px_frame
        
        # Group moving frames into segments
        labeled_array, num_features = label(is_moving)
        all_turning_angles = []

        for i in range(1, num_features + 1):
            segment_indices = np.where(labeled_array == i)[0]
            
            # Segment must be long enough to calculate vectors
            if len(segment_indices) > WINDING_WINDOW_FRAMES * 2:
                segment_coords = valid_coords[segment_indices]
                
                # Calculate vectors: Head position now vs Head position X frames ago
                vectors = segment_coords[WINDING_WINDOW_FRAMES:] - segment_coords[:-WINDING_WINDOW_FRAMES]
                
                # Filter out tiny vectors that might cause noise in angle calculation
                window_displacements = np.sqrt(np.sum(vectors**2, axis=1))
                # Hardcoded 1.0px as minimal movement for vector validity to avoid arctan noise
                moving_windows_mask = window_displacements > 1.0 
                
                if np.sum(moving_windows_mask) < 2: 
                    continue

                moving_vectors = vectors[moving_windows_mask]
                
                # Calculate angles using arctan2
                angles = np.arctan2(moving_vectors[:, 1], moving_vectors[:, 0])
                
                # Calculate change in angle
                turning_angles_seg = np.diff(angles)
                
                # Normalize angles to be between -pi and pi
                turning_angles_seg = (turning_angles_seg + np.pi) % (2 * np.pi) - np.pi
                
                all_turning_angles.extend(turning_angles_seg)

        if not all_turning_angles:
            return 0.0
            
        # Sum of absolute angles divided by 2*pi (360 degrees)
        total_abs_rotation = np.sum(np.abs(all_turning_angles))
        absolute_circles = total_abs_rotation / (2 * np.pi)
        
        return absolute_circles

    except Exception as e:
        print(f"Warning: Error calculating circles: {e}")
        return 0.0

def analyze_dlc_data(file_path):
    """
    Analyze a single DeepLabCut CSV file.
    """
    # 1. Load data
    try:
        df = pd.read_csv(file_path, header=[0, 1, 2])
    except Exception as e:
        raise ValueError(f"Failed to read CSV file: {e}")

    # Extract columns
    part_cols = [col for col in df.columns if col[1] == BODY_PART]
    if not part_cols:
        raise ValueError(f"Body part '{BODY_PART}' not found in CSV columns.")

    data_map = {}
    for col in part_cols:
        coord_name = col[2]  # x, y, or likelihood
        data_map[coord_name] = df[col]
    
    part_df = pd.DataFrame(data_map)

    # 2. Filter & Interpolate
    # Keep a copy of raw likelihood for the rotation function before interpolation logic
    raw_likelihood = part_df['likelihood'].copy()

    low_conf_mask = part_df['likelihood'] < LIKELIHOOD_THRESH
    part_df.loc[low_conf_mask, ['x', 'y']] = np.nan
    part_df['x'] = part_df['x'].interpolate(method='linear')
    part_df['y'] = part_df['y'].interpolate(method='linear')

    # 3. Standard Metrics (Distance, Speed, Center)
    part_df['x_cm'] = pixel_to_cm(part_df['x'])
    part_df['y_cm'] = pixel_to_cm(part_df['y'])

    delta_x = part_df['x_cm'].diff()
    delta_y = part_df['y_cm'].diff()
    step_distance = np.sqrt(delta_x ** 2 + delta_y ** 2)

    # Center Zone Logic
    center_start = (FIELD_SIZE_CM - CENTER_SIZE_CM) / 2
    center_end = (FIELD_SIZE_CM + CENTER_SIZE_CM) / 2
    is_in_center = (
        (part_df['x_cm'] >= center_start) & (part_df['x_cm'] <= center_end) &
        (part_df['y_cm'] >= center_start) & (part_df['y_cm'] <= center_end)
    )

    total_distance_m = step_distance.sum() / 100.0
    in_center_movement = step_distance[(is_in_center) & (is_in_center.shift(1, fill_value=False))]
    in_center_distance_m = in_center_movement.sum() / 100.0
    is_entering = (is_in_center) & (~is_in_center.shift(1, fill_value=False))
    num_entries = is_entering.sum()

    if FRAME_RATE > 0 and len(part_df) > 1:
        total_time_s = (len(part_df) - 1) / FRAME_RATE
        speed_m_per_s = total_distance_m / total_time_s
    else:
        speed_m_per_s = np.nan

    # 4. Rotation Metric (Absolute Cumulative Circles)
    # We use the interpolated x/y but the raw likelihood for valid segment detection
    abs_circles = calculate_absolute_circles(part_df['x'], part_df['y'], raw_likelihood)

    return {
        'file_path': file_path,
        'total_distance_m': total_distance_m,
        'center_entries': num_entries,
        'center_distance_m': in_center_distance_m,
        'average_speed_mps': speed_m_per_s,
        'absolute_cumulative_circles': abs_circles 
    }


def main():
    print("Starting Open Field Behavior Analysis...")
    
    if not CSV_FILE_PATHS:
        print("Error: No CSV files specified in CSV_FILE_PATHS. Please edit the script.")
        return

    results = []

    for file_path in CSV_FILE_PATHS:
        if not os.path.exists(file_path):
            print(f"Warning: File not found, skipping: {file_path}")
            continue

        try:
            print(f"Processing: {file_path}")
            result = analyze_dlc_data(file_path)
            results.append(result)
            
            print(f"  -> Distance: {result['total_distance_m']:.2f} m")
            print(f"  -> Speed: {result['average_speed_mps']:.3f} m/s")
            print(f"  -> Center Entries: {result['center_entries']}")
            print(f"  -> Abs. Circles: {result['absolute_cumulative_circles']:.2f}") 
            print("-" * 30)
            
        except Exception as e:
            print(f"Error analyzing {file_path}: {e}")
            traceback.print_exc()

    if results:
        summary_df = pd.DataFrame(results)
        
        # Reorder columns
        cols = [
            'file_path', 
            'total_distance_m', 
            'average_speed_mps', 
            'center_entries', 
            'center_distance_m', 
            'absolute_cumulative_circles'
        ]
        summary_df = summary_df[cols]
        
        summary_df.to_csv(OUTPUT_FILENAME, index=False, float_format='%.3f', encoding='utf-8')
        print(f"\nAnalysis complete. Summary saved to: {os.path.abspath(OUTPUT_FILENAME)}")
    else:
        print("\nAnalysis finished, but no valid results were generated.")


if __name__ == "__main__":
    main()
